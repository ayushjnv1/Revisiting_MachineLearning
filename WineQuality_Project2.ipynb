{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Import Preprocessing Libraries\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier,  export_graphviz\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.externals import joblib "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data file using Pandas  \n",
    "df1=pd.read_csv('winequality_red.csv')\n",
    "#df1=pd.read_csv('winequality_red.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using isnull() function for finding null values   \n",
    "print(df1.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Representation for finding null values using Heat Map\n",
    "sns.heatmap(df1.isnull())\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.describe(include='all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df1.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_count=df1['quality'].value_counts()\n",
    "print(c_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visual Representation of the dependent variable distribution in the dataset\n",
    "sns.set(rc={'figure.figsize':(12,7)})\n",
    "quality_c=df1['quality']\n",
    "df1_count=sns.countplot(x=quality_c, data=df1)\n",
    "plt.title(\"Class Distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.pairplot(df1, hue=\"quality\")\n",
    "plt.figure(figsize=(30, 30))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analysis the correlation in the dataset\n",
    "corr = df1.corr()\n",
    "print(corr)\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.heatmap(corr[(corr >= 0.4) | (corr <= -0.4)], \n",
    "            cmap='viridis', vmax=1.0, vmin=-1.0, linewidths=0.2,\n",
    "            annot=True, annot_kws={\"size\": 12}, square=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_wines = df1.shape[0]\n",
    "\n",
    "# Number of wines with quality rating above 6 considered good quality\n",
    "quality_above_6 = df1.loc[(df1['quality'] > 6)]\n",
    "n_above_6 = quality_above_6.shape[0]\n",
    "\n",
    "# Number of wines with quality rating below 5 considered not appropiate quality (Bad)\n",
    "quality_below_5 = df1.loc[(df1['quality'] < 5)]\n",
    "n_below_5 = quality_below_5.shape[0]\n",
    "\n",
    "# Number of wines with quality rating between 5 to 6 considered average quality \n",
    "quality_between_5 = df1.loc[(df1['quality'] >= 5) & (df1['quality'] <= 6)]\n",
    "n_between_5 = quality_between_5.shape[0]\n",
    "\n",
    "# Percentage of wines with quality rating above 6\n",
    "greater_percent = n_above_6*100/n_wines\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of wine data: {}\".format(n_wines))\n",
    "print(\"Wines with rating 7 and above: {}\".format(n_above_6))\n",
    "print(\"Wines with rating less than 5: {}\".format(n_below_5))\n",
    "print(\"Wines with rating 5 and 6: {}\".format(n_between_5))\n",
    "print(\"Percentage of wines with quality 7 and above: {:.2f}%\".format(greater_percent))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of the data type in the feature space\n",
    "df = pd.DataFrame(df1)\n",
    "df.plot.hist(alpha=0.5, bins=15, grid=True, legend=None)  \n",
    "plt.xlabel(\"Feature value\")\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try eliminating skewness uisng squareroot function \n",
    "df_pow = df1.apply(np.sqrt)\n",
    "df_pow.plot.hist(alpha=0.5, bins=15, grid=True, legend=None)\n",
    "plt.xlabel(\"Feature value\")\n",
    "plt.title(\"Histogram\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define quality into three target classes \n",
    "def isQuality(quality):\n",
    "    if quality > 6:\n",
    "        return 1\n",
    "    if (quality >= 5) and (quality <= 6):\n",
    "        return 2\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['isQuality'] = df1['quality'].apply(isQuality)\n",
    "print('New Classes are defined for the quality of wines:\\n',df['isQuality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numerical representation of the skweness in the feature set\n",
    "df2=df1.drop('quality', axis=1)\n",
    "print(df.skew())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Signmoid Function established to deal with skewness\n",
    "def sigmoid(x):\n",
    "    e = np.exp(1)\n",
    "    y = 1/(1+e**(-x))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in df2.columns:\n",
    "    if df2.skew().loc[col]>0.55:\n",
    "        df2[col]=sigmoid(df2[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seprate Data into features and target set\n",
    "feature_data=df2\n",
    "target_class=df1['isQuality']\n",
    "print(feature_data.shape)\n",
    "print(target_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the feature_space values \n",
    "sc = StandardScaler()\n",
    "feature_data_std = sc.fit_transform(feature_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the target variable \n",
    "target_class=df1['isQuality'].values.reshape(-1,1)\n",
    "print(target_class.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(feature_data_std, target_class, random_state = 83,test_size=0.28)\n",
    "[subset.shape for subset in [x_train,y_test,x_train,y_test]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function for three classifiers to find best parameters to train and test the model. \n",
    "def grid_search(estimator, clf, x_train, x_test, y_train, y_test):\n",
    "    if estimator == 'SVM':\n",
    "        # Support Vector Machine\n",
    "        svc_params = {'C':[0.0001, 0.001, 0.01, 0.1, 1.0, 10.0, 100.0, 1000.0],\n",
    "                      'kernel': ['rbf', 'poly', 'sigmoid', 'linear']}\n",
    "        grid_svc = GridSearchCV(SVC(), svc_params)\n",
    "        grid_svc.fit(x_train, y_train)\n",
    "        # SVC best estimator\n",
    "        svc = grid_svc.best_estimator_\n",
    "        print(\"Best Parameters for SVM: \", grid_svc.best_estimator_)\n",
    "        print(\"Best Score for SVM: \", grid_svc.best_score_)\n",
    "        print(\"******************************************\")\n",
    "        return svc\n",
    "    elif estimator == 'DecisionTree':\n",
    "    \n",
    "        # Decision Tree\n",
    "        dtree_params = {\"criterion\": [\"gini\", \"entropy\"], \"max_depth\": list(range(2,30,1)),\"min_samples_leaf\": list(range(5,20,1))}\n",
    "        grid_dtree = GridSearchCV(DecisionTreeClassifier(), dtree_params)\n",
    "        grid_dtree.fit(x_train, y_train)\n",
    "        # tree best estimator\n",
    "        tree_clf = grid_dtree.best_estimator_\n",
    "        print(\"Best Parameters for Decision Tree: \", grid_dtree.best_estimator_)\n",
    "        print(\"Best Score for Decision Tree: \", grid_dtree.best_score_)\n",
    "        print(\"******************************************\")\n",
    "        return tree_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define classification function\n",
    "def apply_classification(estimator, clf, x_train, x_test, y_train, y_test):\n",
    "    #Find the best parameter by grid search\n",
    "    grid_clf = grid_search(estimator, clf, x_train, x_test, y_train, y_test)\n",
    "    \n",
    "    # 0.28% data randomly selected as a validation set.\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.28, random_state=83)\n",
    "    \n",
    "    scores = cross_val_score(grid_clf, x_train, y_train, cv=10)\n",
    "    print(\"Mean Accuracy of Cross Validation: %\", round(scores.mean()*100,2))\n",
    "    print(\"Std of Accuracy of Cross Validation: %\", round(scores.std()*100))\n",
    "    print(\"==============================================\")\n",
    "    \n",
    "    #Predict the test data as selected classifier\n",
    "    clf_prediction = grid_clf.predict(x_test)\n",
    "    _accuracy = sum(y_test == clf_prediction)/len(y_test)\n",
    "    print(\"Accuracy of\",estimator,\":\",_accuracy*100)\n",
    "    \n",
    "    #print confusion matrix and accuracy score before best parameters\n",
    "    _conf_matrix = confusion_matrix(y_test, clf_prediction)\n",
    "    print(\"Confusion matrix of\",estimator,\":\\n\", _conf_matrix)\n",
    "    print(\"==========================================\")\n",
    "    \n",
    "    print(\"Classification Report: \\n {}\".format (classification_report(y_test, clf_prediction)))\n",
    "    return grid_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVC()\n",
    "apply_classification('SVM', svm, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier()\n",
    "dt_classifier = apply_classification('DecisionTree', dt, x_train, x_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lastly Save the model for futher use\n",
    "joblib.dump(dt_classifier, 'wine_quality.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
